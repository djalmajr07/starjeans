{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acd5b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T22:15:51.844588Z",
     "start_time": "2021-10-13T22:15:41.945048Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-48872e841ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;31m# data colletion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_collection\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data collectin done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-48872e841ab7>\u001b[0m in \u001b[0;36mdata_collection\u001b[1;34m(url, headers)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mheaders_showroom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mpage_showroom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murl_showroom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders_showroom\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0msoup_showroom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_showroom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import logging\n",
    "\n",
    "#  DATA COLLECTION\n",
    "\n",
    "def data_collection (url, headers):\n",
    "\n",
    "    # request to URL\n",
    "    page_base = requests.get( url, headers=headers )\n",
    "    \n",
    "    # Beautifoul soup object\n",
    "    soup_base = BeautifulSoup(page_base.text, 'html.parser')\n",
    "\n",
    "    # PAGE WITH ALL ITENS SHOWN\n",
    "\n",
    "    total_item = soup_base.find_all( 'h2', class_='load-more-heading' )[0].get('data-total')\n",
    "\n",
    "\n",
    "    url_showroom = url + '?page-size=' + total_item\n",
    "    url_showroom\n",
    "\n",
    "    headers_showroom = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    page_showroom = requests.get( url_showroom, headers=headers_showroom )\n",
    "\n",
    "    soup_showroom = BeautifulSoup(page_showroom.text, 'html.parser')\n",
    "\n",
    "    #================================== PRODUCT DATA ================================================\n",
    "    products_base=soup_showroom.find( 'ul', class_='products-listing small')\n",
    "    product_list_base = products_base.find_all( 'article', class_='hm-product-item')\n",
    "\n",
    "    # product id\n",
    "\n",
    "    product_id_base = [p.get( 'data-articlecode' ) for p in product_list_base]\n",
    "\n",
    "    # product category\n",
    "    product_category_base = [p.get( 'data-category' ) for p in product_list_base]\n",
    "\n",
    "    # product name\n",
    "    product_list_base = products_base.find_all( 'a', class_='link' )\n",
    "    product_name_base = [p.get_text() for p in product_list_base]\n",
    "\n",
    "    # price\n",
    "    product_list_base = products_base.find_all( 'span', class_='price regular' )\n",
    "    product_price_base = [p.get_text() for p in product_list_base]\n",
    "\n",
    "\n",
    "    # JOIN\n",
    "    data=pd.DataFrame([product_id_base, product_category_base, product_name_base, product_price_base]).T\n",
    "    data.columns=['product_id', 'product_category', 'product_name', 'product_price']\n",
    "\n",
    "    # ALL PRODUCTS LINK\n",
    "    prod_link01=soup_showroom.find_all('div', 'image-container')\n",
    "    prod_link02=[p.find('a') for p in prod_link01]\n",
    "    prod_link=[p.get('href') for p in prod_link02]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# DATA COLLETION BY PRODUCT\n",
    "\n",
    "def data_collection_by_product( data, headers ):\n",
    "\n",
    "    # empty dataframe\n",
    "    df_compositions = pd.DataFrame()\n",
    "\n",
    "    # unique columns for all products\n",
    "    aux = []\n",
    "\n",
    "    df_pattern = pd.DataFrame(columns=['Art. No.', 'Composition', 'Fit', 'Product safety',\n",
    "                                       'Size', 'More sustainable materials'])\n",
    "    for i in range(len(data)):\n",
    "        # API request\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "        logger.debug('Prouct: %s', url)\n",
    "        page = requests.get(url, headers=headers)\n",
    "\n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # ==================== color name ====================================\n",
    "        product_list = soup.find_all('a', class_='filter-option miniature active') + soup.find_all('a', class_='filter-option miniature')\n",
    "        color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "        # product id\n",
    "        product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "        df_color = pd.DataFrame([product_id, color_name]).T\n",
    "        df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "        for j in range(len(df_color)):\n",
    "            # API request\n",
    "            url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "            logger.debug('Color: %s', url)\n",
    "            \n",
    "            page = requests.get(url, headers=headers)\n",
    "\n",
    "            # Beautiful Soup object\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "            # ===================== Product Name =========================\n",
    "            product_name = soup.find_all('h1', class_='primary product-item-headline')\n",
    "\n",
    "            if len(product_name) > 0:\n",
    "                product_name = product_name[0].get_text()\n",
    "\n",
    "                # ===================== Product Price =========================\n",
    "                product_price = soup.find_all('div', class_='primary-row product-item-price')\n",
    "                product_price = re.findall(r'\\d+\\.?\\d+', product_price[0].get_text())[0]\n",
    "\n",
    "                # ==================== composition ====================================\n",
    "                product_composition_list = soup.find_all('div', class_='pdp-description-list-item')\n",
    "                product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composition_list]\n",
    "\n",
    "                if len(product_composition) > 0:\n",
    "                    # rename dataframe\n",
    "                    df_composition = pd.DataFrame(product_composition).T\n",
    "\n",
    "                    df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "                    # delete first row\n",
    "                    df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "                    # remove pocket lining, shell and lining\n",
    "                    df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining: ', '', regex=True)\n",
    "                    df_composition['Composition'] = df_composition['Composition'].replace('Shell: ', '', regex=True)\n",
    "                    df_composition['Composition'] = df_composition['Composition'].replace('Lining: ', '', regex=True)\n",
    "\n",
    "                    # garantee the same number of columns\n",
    "                    df_composition = pd.concat([df_pattern, df_composition], axis=0)\n",
    "\n",
    "                    # rename columns\n",
    "                    df_composition.columns = ['product_id', 'composition', 'fit', 'product_safety', 'size', 'sustainable']\n",
    "                    df_composition['product_name'] = product_name\n",
    "                    df_composition['product_price'] = product_price\n",
    "\n",
    "                    # keep new columns if it shows up\n",
    "                    aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "                    # merge data color + composition\n",
    "                    df_composition = pd.merge(df_composition, df_color, how='left', on='product_id')\n",
    "\n",
    "                    # all products\n",
    "                    df_compositions = pd.concat([df_compositions, df_composition], axis=0)\n",
    "\n",
    "    # Join Showroom data + details\n",
    "    df_compositions['style_id'] = df_compositions['product_id'].apply(lambda x: x[:-3])\n",
    "    df_compositions['color_id'] = df_compositions['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "    # scrapy datetime\n",
    "    df_compositions['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return df_compositions\n",
    "\n",
    "# DATA CLEANING\n",
    "\n",
    "def data_cleaning(df_compositions):\n",
    "\n",
    "    data.rename(columns={'scrapy_datetime_base': 'scrapy_datetime', 'Fit': 'fit', \n",
    "                         'Composition': 'composition', 'Size': 'size', 'Prouct safety': 'product_safety'}, inplace=True)\n",
    "\n",
    "    # product_id\n",
    "    data=data.dropna(subset=['product_id'])\n",
    "    data['product_id']=data['product_id'].astype('int64')\n",
    "\n",
    "    # product_name  \n",
    "    data['product_name']=data['product_name'].apply(lambda x: x.replace('__', ' ').lower().strip()) \n",
    "    data['product_name']=data['product_name'].apply(lambda x: x.replace(' ', '_').lower().strip()) \n",
    "\n",
    "    # product_price  \n",
    "    # data['product_price']=data['product_price'].apply(lambda x: x.replace('$', ' ')).astype(float)\n",
    "\n",
    "    # scrapy_datetime \n",
    "    data['scrapy_datetime']=pd.to_datetime(data['scrapy_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # style_id              \n",
    "    data['style_id']=data['style_id'].astype('int64')\n",
    "\n",
    "    # color_id              \n",
    "    data['color_id']=data['color_id'].astype('int64')\n",
    "\n",
    "    # color name\n",
    "    data['color_name'] = data['color_name'].apply( lambda x: x.replace( ' ', '_' ).replace( '/', '_' ).lower() if pd.notnull( x ) else x )\n",
    "\n",
    "    # fit\n",
    "    data['fit'] = data['fit'].apply( lambda x: x.replace( ' ', '_' ).lower() if pd.notnull( x ) else x )\n",
    "\n",
    "    # Size number\n",
    "    data['size_number']=data['size'].apply(lambda x: re.search('\\d{3}cm',x).group(0) if pd.notnull(x) else x)\n",
    "    data['size_number']=data['size_number'].apply(lambda x: re.search('\\d+',x).group(0) if pd.notnull(x) else x)\n",
    "\n",
    "    # Size model\n",
    "    data['size_model'] = data['size'].str.extract( '(\\d+/\\\\d+)' )\n",
    "\n",
    "    # composition\n",
    "    data =data[~data['composition'].str.contains('Pocket lining:', na=False)]\n",
    "    data =data[~data['composition'].str.contains('Lining:', na=False)]\n",
    "    data =data[~data['composition'].str.contains('Shell:', na=False)]\n",
    "    data =data[~data['composition'].str.contains('Pocket:', na=False)]\n",
    "\n",
    "    # drop duplicates\n",
    "    data= data.drop_duplicates(subset=['product_id', 'product_name', 'product_price',\n",
    "                                       'scrapy_datetime', 'style_id', 'color_id', 'color_name', 'fit'], keep='last')\n",
    "    # reset index\n",
    "    data= data.reset_index(drop=True)\n",
    "\n",
    "    # break composition by comma\n",
    "    df1= data['composition'].str.split(',',expand=True)\n",
    "\n",
    "    # cotton | polyester | elastano | elastarell\n",
    "    df_ref=pd.DataFrame(index=np.arange(len(data)),columns=['cotton' , 'polyester' , 'elastane' , 'elasterell'])\n",
    "\n",
    "    # cotton\n",
    "    df_cotton = df1[0]\n",
    "    df_cotton.name='cotton'\n",
    "\n",
    "    df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "    df_ref = df_ref.iloc[: , ~df_ref.columns.duplicated(keep='last')]\n",
    "    df_ref['cotton']=df_ref['cotton'].fillna('Cotton 0%')\n",
    "\n",
    "    # polyester\n",
    "    df_polyester=df1.loc[df1[1].str.contains('Polyester' , na=True), 1]\n",
    "    df_polyester.name='polyester'\n",
    "\n",
    "    df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "    df_ref = df_ref.iloc[: , ~df_ref.columns.duplicated(keep='last')]\n",
    "    df_ref['polyester']=df_ref['polyester'].fillna('Polyester 0%')\n",
    "\n",
    "    # elastano\n",
    "    df_elastane=df1.loc[df1[1].str.contains('Elastane', na=True), 1]\n",
    "    df_elastane.name='elastane'\n",
    "\n",
    "    # combine elastane from both columns 1 and 2\n",
    "    df_elastane=df_elastane.combine_first(df1[2])\n",
    "\n",
    "    df_ref = pd.concat([df_ref, df_elastane], axis=1)\n",
    "    df_ref = df_ref.iloc[: , ~df_ref.columns.duplicated(keep='last')]\n",
    "    df_ref['elastane']=df_ref['elastane'].fillna('Elastane 0%')\n",
    "\n",
    "    # elastarell\n",
    "    df_elasterell=df1.loc[df1[1].str.contains('Elasterell' , na=True), 1]\n",
    "    df_elasterell.name='elasterell'\n",
    "\n",
    "    df_ref = pd.concat([df_ref, df_elasterell], axis=1)\n",
    "    df_ref = df_ref.iloc[: , ~df_ref.columns.duplicated(keep='last')]\n",
    "    df_ref['elasterell']=df_ref['elasterell'].fillna('Elasterell 0%')\n",
    "\n",
    "    # final join\n",
    "    data=pd.concat([data, df_ref], axis=1)\n",
    "    data=data.dropna(how='all').reset_index(drop=True)\n",
    "    data = data.iloc[: , ~data.columns.duplicated(keep='last')]\n",
    "\n",
    "    # format composition data\n",
    "    data['cotton']    =data['cotton']    .apply( lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "    data['polyester'] =data['polyester'] .apply( lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "    data['elastane']  =data['elastane']  .apply( lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "    data['elasterell']=data['elasterell'].apply( lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "\n",
    "    data['product_id']=data['product_id'].astype('int64')\n",
    "    data['style_id']  =data['style_id'].astype('int64')\n",
    "    data['color_id']  =data['color_id'].astype('int64')\n",
    "\n",
    "    # drop columns\n",
    "    data = data.drop( columns=['size', 'product_safety', 'composition'], axis=1 )\n",
    "\n",
    "    # drop duplicates\n",
    "    data = data.drop_duplicates()\n",
    "    data=data.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "\n",
    "# DATA INSERT\n",
    "\n",
    "def data_insert(df_data):\n",
    "\n",
    "    data_insert = df_data[[\n",
    "        'product_id',\n",
    "        'style_id',\n",
    "        'color_id',\n",
    "        'product_name',\n",
    "        'color_name',\n",
    "        'fit',\n",
    "        'product_price',\n",
    "        'size_number',\n",
    "        'size_model',\n",
    "        'cotton',\n",
    "        'polyester',\n",
    "        'elastane',\n",
    "        'elasterell',\n",
    "        'sustainable',\n",
    "        'scrapy_datetime'\n",
    "        ]]\n",
    "\n",
    "\n",
    "    # create table\n",
    "    conn=create_engine('sqlite:///database_hm.sqlite', echo=False)\n",
    "\n",
    "    # data insert\n",
    "    data_insert.to_sql('vitrine', con=conn, if_exists='append', index=False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path = 'C:/Users/djalmaluiz/DS/starjeans/'\n",
    "    if not os.path.exists( path + 'Logs' ):\n",
    "        os.makedirs( path + 'Logs' )\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename='C:/Users/djalmaluiz/DS/starjeans/Logs/hm_etl.log',\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "        datefmt= '%Y-%m-%d %H:%M:%S:'\n",
    "        )\n",
    "\n",
    "    logger = logging.getLogger('webscraping_hm')\n",
    "\n",
    "\n",
    "\n",
    "    # parameters\n",
    "    url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    \n",
    "    \n",
    "    # data colletion\n",
    "    data=data_collection (url, headers)\n",
    "    logger.info('data collectin done')    \n",
    "    \n",
    "    # data colletion by product\n",
    "    df_compositions = data_collection_by_product(data, headers)\n",
    "    logger.info('data collect by product done')\n",
    "    \n",
    "    # data cleaning\n",
    "    data_product_cleaned =  data_cleaning(df_compositions)\n",
    "    logger.info('data cleaning done')\n",
    "    \n",
    "    # data insertion\n",
    "    data_insert(data_product_cleaned)\n",
    "    logger.info('data insertion done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
